---
title: "HarvardX: PH125.9x Capstone - MovieLens Project"
author: "Friederike David"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
---

*This project is part of the*
*[HarvardX's Data Science Capstone](https://www.edx.org/course/data-science-capstone) course,*
*which is the last out of nine courses within the*
*[HarvardX's Data Science Professional Certificate](https://www.edx.org/professional-certificate/harvardx-data-science).*


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F,  message = F, 
                      fig.align = "center", fig.width = 9)

# employed packages
pkgs <- c(
  "here",         # locate files within project
  "tidyverse",    # load multiple 'tidyverse' packages in a single step
  "stringr",      # string operations
  "data.table",   # fast reading and writing of tabular data
  "lubridate",    # date/time operations (masks here::here()!)
  "caret",        # classification and regression training
  "glmnet",       # compute penalized regression
  "rpart",        # recursive partitioning and regression trees
  "patchwork",    # plotting
  "scales"        # plotting
)
lapply(pkgs, function(pkg) {
  if (!require(pkg, character.only = T)) 
    install.packages(pkg, repos = "http://cran.us.r-project.org")
})

# project setup: use project directory/data to store reusable input data
dir.create(here::here("data"), showWarnings = F)

# plotting theme
theme_set(theme_minimal())

# R version (to use correct set.seed call)
rver <- paste0(sessionInfo()$R.version$major, sessionInfo()$R.version$minor) %>% 
  str_remove_all("\\.") %>% as.integer()
```


# Introduction

Movie recommendation systems are a common application of machine learning models
that aim to predict how a given user would rate a given movie in order to
generate recommendations for movies a given user is likely to enjoy.
Such recommendation systems are employed for example by streaming services like
Netflix to enhance the user experience and therefore well-preforming models can
create considerable business value.  

In this project, a movie recommendation system based on the 
[MovieLens 10M Dataset](https://grouplens.org/datasets/movielens/10m/) is 
implemented, which predicts movie recommendations for a given movie and user 
within the dataset from a set of input features.
The input dataset consists of about 10 million movie ratings with additional 
information e.g. on movie genre and rating datetime, which are used to build a
machine learning model as detailed in the methods sections.  

Briefly, as first step the validation subset that is exclusively used for the
final model evaluation is derived from the input dataset. The remaining data 
points are explored and cleaned before deciding on a modelling approach and then
further split into a training and test set for model optimization.
Finally, model performance will be evaluated in the results section based on the
validation set.
Both for traning and evaluating the model, the root mean squared error (RMSE) 
between predicted and true ratings is used as loss function.


# Methods

## Data input

The publicly available 
[MovieLens 10M Dataset](https://grouplens.org/datasets/movielens/10m/)
is downloaded and split into a set for model development (`edx`) and a 
validation set (`validation`) using a modified version of the R code provided in
the course materials.
For computational efficiency when re-running the analysis, the downloaded 
dataset and prepared data objects are saved in `./data/` and re-used if already 
existing.  

```{r data_input, include=F}
if (!file.exists(here::here("data/input_data.RData"))) {
  
  # stable download url for MovieLens 10M dataset
  url <- "http://files.grouplens.org/datasets/movielens/ml-10m.zip"
  
  dl <- here::here("data/movielens_ml-10m.zip")
  if (!file.exists(dl)) download.file(url, dl)
  
  ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                   col.names = c("userId", "movieId", "rating", "timestamp"))
  
  movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
  colnames(movies) <- c("movieId", "title", "genres")
  movies <- as.data.frame(movies) %>% 
    mutate(movieId = as.numeric(levels(movieId))[movieId],
           title = as.character(title),
           genres = as.character(genres))
  
  movielens <- left_join(ratings, movies, by = "movieId")
  
  # validation set will be 10% of MovieLens data
  if (rver < 360) {set.seed(1)} else {set.seed(1, sample.kind = "Rounding")}
  test_index <- createDataPartition(y = movielens$rating, times = 1, p = .1, list = F)
  edx <- movielens[-test_index,]
  temp <- movielens[test_index,]
  
  # make sure userId and movieId in validation set are also in edx set
  validation <- temp %>% 
    semi_join(edx, by = "movieId") %>%
    semi_join(edx, by = "userId")
  
  # add rows removed from validation set back into edx set
  removed <- anti_join(temp, validation)
  edx <- rbind(edx, removed)
  
  rm(url, dl, ratings, movies, test_index, temp, movielens, removed)
  save(edx, validation, file = here::here("data/input_data.RData"))
  
} else {
  load(here::here("data/input_data.RData"))
}
```


## Data exploration and feature engineering

For developing a well-performing machine learning model, it is essential to
explore the dataset before deciding on a modeling approach.
Therefore, in this section the structure and properties of the training set are
examined and potentially relevant input features are prepared.


### Overall structure

```{r data_exploration_overall, echo=F}
# structure of data set
glimpse(edx)

# number of unique elements, e.g. movies and users
n <- edx %>% summarize_all(~ unique(.x) %>% length())
genres.single <- str_split(edx$genres, "\\|") %>% unlist() %>% unique()

# # year of publication in parentheses included at the end of every title?
# all(str_detect(edx$title, "(?<=\\()[0-9]{4}(?=\\)$)"))
```

The training dataset contains `r ncol(edx)` columns
(`r paste0(colnames(edx), collapse = ", ")`) and `r nrow(edx)` rows.
It comprises `r n$userId` user IDs and `r n$movieId` movie IDs/`r n$title`
titles as well as `r length(genres.single)` genre categories and `r n$genres`
combinations of one or more genres.
Each title also includes the publication year in parentheses.

Trends regarding sparsity within the user ID x movie ID rating matrix are
visualized in the following plots.

```{r data_exploration_sparsity, fig.height=5, echo=F}
# visualize rating matrix on a small random subset of users and movies
p1 <- edx %>%
  filter(movieId %in% sample(movieId, 100)) %>%
  filter(userId %in% sample(userId, 100)) %>%
  mutate_at(vars(movieId, userId), ~ as.character(.x)) %>%
  ggplot(aes(movieId, userId, fill = rating)) +
  geom_tile() +
  labs(x = "Movies", y = "Users", fill = "Rating") +
  theme(axis.text = element_blank(),
        legend.position = "bottom")

# visualize distribution of the proportion of rated movies per user
mprop <- group_by(edx, userId) %>% summarize(prop = n()/n$movieId)
p2 <- ggplot(mprop, aes(x = "", y = prop)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_log10(labels = scales::percent) +
  labs(x = NULL, y = "Fraction of rated movies per user")

# visualize distribution of the proportion of rating users per movie
uprop <- group_by(edx, movieId) %>% summarize(prop = n()/n$userId)
p3 <- ggplot(uprop, aes(x = "", y = prop)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_log10(labels = scales::percent) +
  labs(x = NULL, y = "Fraction of rating users per movie")

# print multi-panel plot
p1 | (p2 / p3) + plot_layout(nrow = 2, widths = c(3, 2))
```

A wide range of rated movies per user and rating users per movie is apparent
with some users having rated up to
`r max(mprop$prop * 100) %>% round(digits = 2)` % of available movies and some
movies having been rated by up to
`r max(uprop$prop * 100) %>% round(digits = 2)` % of available users.


### Ratings

```{r data_exploration_ratings, echo=F}
# range and distribution of ratings
ggplot(edx, aes(x = rating)) +
  geom_bar() +
  labs(x = "Rating", y = "Count")
```

Ratings are recorded within a `r max(edx$rating)`-star system that allows for
half-star and full-star ratings.
In general, full-star ratings are more common than half-star ratings, although
the overall distribution is similar with 4 stars as most frequent full-star
rating and 3.5 stars as most frequent half-star rating.


```{r data_exploration_ratings_n, echo=F}
# average rating by number of ratings per movie
edx %>%
  group_by(movieId) %>%
  summarize(n = n(), avg_rating = mean(rating)) %>%
  ggplot(aes(n, avg_rating)) +
  geom_point() +
  ylim(c(0, 5)) +
  labs(x = "Number of ratings per movie", y = "Average rating by movie")
```

On average, movies with a higher number of ratings, i.e. popular movies, tend to
have a higher rating than movies with a low number of ratings, for which a broad
range of average ratings is observed.

### Movies

```{r data_exploration_movies, echo=F}
# number of ratings per movie
edx %>% 
  group_by(movieId) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(n)) +
  geom_histogram() +
  scale_x_log10() +
  labs(x = "Ratings per movie", y = "Count")
```


### Users

```{r data_exploration_users, echo=F}
# number of ratings per user
edx %>% 
  group_by(userId) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(n)) +
  geom_histogram() +
  scale_x_log10() +
  labs(x = "Ratings per user", y = "Count")
```


### Genres

```{r data_exploration_genres, echo=F}
# available genre combinations
edx %>% group_by(genres) %>%
  summarize(n = n(), mean_rating = mean(rating)) %>%
  arrange(desc(n)) %>%
  select("Genre combination" = genres, "Number of ratings" = n,
         "Mean rating" = mean_rating) %>%
  head(n = 5) %>%
  knitr::kable(caption = "Top 5 most frequent genre combinations")
```


```{r data_exploration_ratings_genre, echo=F}
# rating distribution by main genres
lapply(genres.single, function(genre) {
  edx %>%
    filter(str_detect(genres, genre)) %>%
    mutate(main_genre = genre) %>%
    select(main_genre, rating)
}) %>% bind_rows() %>%
  ggplot(aes(reorder(main_genre, -rating, FUN = mean), rating)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(hjust = 1, angle = 45)) +
  labs(x = "Main genres", y = "Ratings")

# rating distribution by genre combinations (with min. 20000 ratings)
edx %>%
  group_by(genres) %>% filter(n() >= 20000) %>% ungroup() %>%
  ggplot(aes(reorder(genres, -rating, FUN = mean), rating)) +
  geom_boxplot() +
  theme(axis.text.x = element_blank()) +
  labs(x = "Genre combinations", y = "Ratings")

```

A moderate genre effect on ratings is visible.


### Publication year and rating datetime

Since the datetime of ratings is only given as integer timestamp and the
publication year is part of the title, inferred variables are added as possible
additional features. Subsequently, time-related trends are visualized in the
following plots.

```{r features_dates}
# add publication date extracted from title and rating date, year and weekday
edx <- edx %>%
  mutate(publication_year = str_extract(title, "(?<=\\()[0-9]{4}(?=\\)$)"),
         rating_date = as_datetime(timestamp),
         rating_year = year(rating_date),
         rating_weekday = wday(rating_date, label = T, week_start = 1))
```

```{r data_exploration_time, fig.height=12, echo=F}
# average rating over time
p1 <- edx %>%
  mutate(rating_year = as.character(rating_year)) %>%
  group_by(movieId, rating_year) %>%
  summarize(avg_rating = mean(rating)) %>%
  ggplot(aes(rating_year, avg_rating)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0, 5)) +
  labs(x = "Rating year", y = "Average rating by movie")

# average rating by weekday
p2 <- edx %>%
ggplot(aes(rating_weekday, rating)) +
  geom_boxplot() +
  ylim(c(0, 5)) +
  labs(x = "Weekday", y = "Rating")

# relation between publication year and mean rating per movie
p3 <- edx %>%
  group_by(movieId) %>%
  summarize(year = unique(publication_year),
            avg_rating = mean(rating)) %>%
  ggplot(aes(year, avg_rating)) +
  geom_boxplot() +
  scale_x_discrete(breaks = edx$publication_year %>% unique() %>% str_subset("0$")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Publication year", y = "Average rating by movie")

(p1 + p2) / p3 + plot_layout(nrow = 2, heights = c(2, 3))
```

Both publication year and rating year as well as rating weekday seem to have a
rather small effect on ratings.  


## Model specification

For both parameter optimization and model evaluation, the root mean squared 
error (RMSE) with predicted ratings $\hat{Y}$, true ratings $Y$ and number of 
ratings $N$ will be used as loss function:  

$$RMSE = \sqrt{\frac{1}{N}\sum \hat{Y} - Y} $$

```{r fun_rmse}
# function to calculate root mean squared error
RMSE <- function(Y, Y_hat) sqrt(mean((Y - Y_hat)^2))
```


From the preceding data exploration it can be assumed that both movie-specific
and user-specific effects are important to model movie ratings.
Further, the movie genre may provide some additional information on movie 
ratings.
Rating year, rating weekday and publication year, however, seem to have a 
negligible impact on ratings and are therefore not included in the model.  

The resulting model for movie ratings $Y$ can be written as follows:

$$Y = \mu + b_m + b_u + b_g + \epsilon$$

The formula includes the overall average rating $\mu$ as baseline as well as
level-specific feature effects $b$ for movie $m$, user $u$ and movie genre $g$ 
and an error term $\epsilon$.  

As baseline, $\hat{\mu}$ is estimated as the overall average rating.  

```{r mu_hat}
# estimated mean rating
mu_hat <- mean(edx$rating)
```

In a stepwise approach which reflects the assumed relevance of predictor 
variables, the individual effects $\b$ will be estimated according to the
following sequence of equations:

$$\hat{b_m} = \frac{1}{n_m}\sum{Y_m - \hat{\mu}}$$
$$\hat{b_u} = \frac{1}{n_u}\sum{Y_u - \hat{\mu} - \hat{b_m}}$$
$$\hat{b_g} = \frac{1}{n_g}\sum{Y_g - \hat{\mu} - \hat{b_m} - \hat{b_u}}$$


```{r coeff_basic}
movie_basic <- edx %>% 
  group_by(movieId) %>% summarize(b_m = mean(rating - mu_hat))

user_basic <- edx %>% left_join(movie_basic) %>% 
  group_by(userId) %>% summarize(b_u = mean(rating - mu_hat - b_m))

genre_basic <- edx %>% left_join(movie_basic) %>% left_join(user_basic) %>% 
  group_by(genres) %>% summarize(b_g = mean(rating - mu_hat - b_m - b_u))
```


However, since for some movies, users and genres only very few ratings are 
available, regularization of coefficients is additionally used to improve model
performance.
Here, the following function will be minimized to obtain the best value for 
the penalty parameter $\lambda$:

$$\frac{1}{N}\sum{(Y - \mu - b_m - b_u - b_g)^2} + \lambda (\sum{b_m^2} + \sum{b_u^2} + \sum{b_g^2})$$

As in the before in the basic estimation of coefficients, the stepwise approach
is employed.
Since in the regularization approach $\lambda$ is a tunable parameter, the `edx`
set is split into a training and a testing subset to chose the optimal $\lambda$
that minimizes the RMSE in the test set.


```{r split_edx}
# split edx set into training and testing set for model optimization
if (rver < 360) {set.seed(1)} else {set.seed(1, sample.kind = "Rounding")}
train_index <- createDataPartition(edx$rating, p = 0.9, list = F)

train <- edx[train_index,]
tmp <- edx[-train_index,]

# make sure userId and movieId in test set are also in train set
test <- semi_join(tmp, train, by = "movieId") %>% semi_join(train, by = "userId")

# add rows removed from test set back into train set
train <- rbind(train, anti_join(tmp, test))
```

Using the `train` set to calculate regularized coefficients at different values
for $\lambda$ and the `test` set to calculate the corresponding RMSE, the 
optimal value for $\lambda$ that minimizes the RMSE on the test set is selected.


```{r lambda_tuning}
# calculate RSME at different lambdas (regularizing movie, user and genre regects)
lambdas <- seq(0, 10, 0.5)
rmse_reg <- sapply(lambdas, function(lambda) {
  
  # regularized movie effects
  movie_reg <- train %>% 
    group_by(movieId) %>% 
    summarize(b_m = sum(rating - mu_hat)/(lambda + n()))
  
  # regularized user effects
  user_reg <- train %>% 
    left_join(movie_reg, by = "movieId") %>% 
    group_by(userId) %>% 
    summarize(b_u = sum(rating - mu_hat - b_m)/(lambda + n()))
  
  # regularized genre effects
  genre_reg <- train %>% 
    left_join(movie_reg, by = "movieId") %>% 
    left_join(user_reg, by = "userId") %>% 
    group_by(genres) %>% 
    summarize(b_g = sum(rating - mu_hat - b_m - b_u)/(lambda + n()))
  
  # RSME estimation for test set
  test %>% 
    left_join(movie_reg, by = "movieId") %>% 
    left_join(user_reg, by = "userId") %>% 
    left_join(genre_reg, by = "genres") %>% 
    mutate(rating_hat = mu_hat + b_m + b_u + b_g) %>% 
    summarize(rmse = RMSE(rating, rating_hat)) %>% 
    pull(rmse)
})
```


```{r lambda_plot, echo=F}
data.frame(Lambda = lambdas,
           RMSE = rmse_reg) %>% 
  ggplot(aes(Lambda, RMSE)) +
  geom_point()
```

With this optimal value for $\lambda$, the final regularized model coefficients
are calculated.  

```{r coeff_regularized}
# get coefficients for lambda that minimizes the RSME
lambda <- lambdas[which.min(unlist(rmse_reg))]

# calculate the corresponding coefficients for the entire edx set
movie_reg <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_m = sum(rating - mu_hat)/(lambda + n()))
user_reg <- edx %>% 
  left_join(movie_reg, by = "movieId") %>% 
  group_by(userId) %>% 
  summarize(b_u = sum(rating - mu_hat - b_m)/(lambda + n()))
genre_reg <- edx %>% 
  left_join(movie_reg, by = "movieId") %>% 
  left_join(user_reg, by = "userId") %>% 
  group_by(genres) %>% 
  summarize(b_g = sum(rating - mu_hat - b_m - b_u)/(lambda + n()))
```


# Results

After fitting the basic and regularized models as described, performance is 
evaluated by calculating the RMSE on the validation set.
Additionally, the RMSE obtained when using the overall average rating as 
naive prediction is included.  

```{r modelling_evaluation}
# naive prediction with overall mean
rmse_naive_mean <- RMSE(validation$rating, mu_hat)

# basic model
rmse_basic <- validation %>% 
  left_join(movie_basic) %>% 
  left_join(user_basic) %>% 
  left_join(genre_basic) %>% 
  mutate(rating_hat = mu_hat + b_m + b_u + b_g) %>% 
  summarize(rmse = RMSE(rating, rating_hat)) %>% 
  pull(rmse)

# regularized model
rmse_regularized <- validation %>% 
  left_join(movie_reg, by = "movieId") %>% 
  left_join(user_reg, by = "userId") %>% 
  mutate(rating_hat = mu_hat + b_m + b_u) %>% 
  summarize(rmse = RMSE(rating, rating_hat)) %>% 
  pull(rmse)

data.frame(Model = c("naive mean", "simple additive model", "regularized model"),
           RMSE = c(rmse_naive_mean, rmse_basic, rmse_regularized)) %>% 
  knitr::kable(caption = "RSME estimates for different modelling approaches")
```



# Conclusion

Compared to the naive model in which all ratings are predicted as the overall
average with an RMSE of `r rmse_naive_mean`, the simple additive model in which
movie effects, user effects and genre effects are considered yields a 
considerably lower RMSE of `r rmse_basic`.
The regularization of coefficients leads to a further improvement of model
performance, however, with a RMSE of `r rmse_regularized` this improvement is
rather minor.



# Session info

```{r session_info}
sessionInfo()
```

<br>
<br>
